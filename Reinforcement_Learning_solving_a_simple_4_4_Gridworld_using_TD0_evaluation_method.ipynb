{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        # S O O O\n",
        "        # O O O *\n",
        "        # O * O O\n",
        "        # O * 0 T\n",
        "        self.actionSpace = ('U', 'D', 'L', 'R')\n",
        "        self.actions = {\n",
        "            (0, 0): ('D', 'R'),\n",
        "            (0, 1): ('L', 'D', 'R'),\n",
        "            (0, 2): ('L', 'D', 'R'),\n",
        "            (0, 3): ('L', 'D'),\n",
        "            (1, 0): ('U', 'D', 'R'),\n",
        "            (1, 1): ('U', 'L', 'D', 'R'),\n",
        "            (1, 2): ('U', 'L', 'D', 'R'),\n",
        "            (1, 3): ('U', 'L', 'D'),\n",
        "            (2, 0): ('U', 'D', 'R'),\n",
        "            (2, 1): ('U', 'L', 'D', 'R'),\n",
        "            (2, 2): ('U', 'L', 'D', 'R'),\n",
        "            (2, 3): ('U', 'L', 'D'),\n",
        "            (3, 0): ('U', 'R'),\n",
        "            (3, 1): ('U', 'L', 'R'),\n",
        "            (3, 2): ('U', 'L', 'R')\n",
        "        }\n",
        "        self.rewards = {(3, 3): 0.5, (1, 3): -0.3, (2, 1):-0.3, (3, 1):-0.3}#\n",
        "        self.explored = 0\n",
        "        self.exploited = 0\n",
        "\n",
        "    def getRandomPolicy(self):\n",
        "        policy = {}\n",
        "        for state in self.actions:\n",
        "            policy[state] = np.random.choice(self.actions[state])\n",
        "        return policy\n",
        "\n",
        "    def reset(self):\n",
        "        return (0, 0)\n",
        "        \n",
        "    def is_terminal(self, s):\n",
        "        return s not in self.actions\n",
        "\n",
        "    def getNewState(self,state,action):\n",
        "      i, j = zip(state)\n",
        "      row = int(i[0])\n",
        "      column = int(j[0])\n",
        "      if action == 'U':\n",
        "          row -= 1\n",
        "      elif action == 'D':\n",
        "          row += 1\n",
        "      elif action == 'L':\n",
        "          column -= 1\n",
        "      elif action == 'R':\n",
        "          column += 1\n",
        "      return row,column\n",
        "\n",
        "    def chooseAction(self, state, policy, exploreRate):\n",
        "        if exploreRate > np.random.rand():\n",
        "            self.explored += 1\n",
        "            return np.random.choice(self.actions[state])\n",
        "        self.exploited += 1\n",
        "        return policy[state]\n",
        "\n",
        "    def greedyChoose(self, state, values):\n",
        "        actions = self.actions[state]\n",
        "        stateValues = []\n",
        "        for act in actions:\n",
        "            row,column=self.getNewState(state,act)\n",
        "            if (row, column) in values:\n",
        "                stateValues.append(values[(row, column)])\n",
        "        return actions[np.argmax(stateValues)]\n",
        "    \n",
        "    def move(self, state, policy, exploreRate):\n",
        "        action = self.chooseAction(state, policy, exploreRate)\n",
        "        row,column=self.getNewState(state,action)\n",
        "        if (row, column) in self.rewards:\n",
        "            return (row, column),self.rewards[(row, column)]\n",
        "        return (row, column),-0.05\n",
        "    def printVaues(self,values):\n",
        "        line = \"\"\n",
        "        counter = 0\n",
        "        for item in values:\n",
        "            line += f\" | {values[item]} | \"\n",
        "            counter += 1\n",
        "            if counter > 3:\n",
        "                print(line)\n",
        "                print(\"--------------------------------\")\n",
        "                counter = 0\n",
        "                line = \"\"\n",
        "        print(line)\n",
        "        print(\"----------------------------\")\n",
        "        \n",
        "    def printPolicy(self, policy):\n",
        "        line = \"\"\n",
        "        counter = 0\n",
        "        for item in policy:\n",
        "            line += f\" | {policy[item]} | \"\n",
        "            counter += 1\n",
        "            if counter > 3:\n",
        "                print(line)\n",
        "                print(\"----------------------------\")\n",
        "                counter = 0\n",
        "                line = \"\"\n",
        "        print(line)\n",
        "        print(\"----------------------------\")"
      ],
      "metadata": {
        "id": "Hq-5-5RbNPiZ"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enviroment = GridWorld()\n",
        "policy = enviroment.getRandomPolicy()\n",
        "# enviroment.printPolicy(policy)\n",
        "\n",
        "#example optimal policy = {(0, 0): 'R', (0, 1): 'R', (0, 2): 'D', (0, 3): 'D', (1, 0): 'R', (1, 1): 'D', (1, 2): 'D', (1, 3): 'D',\n",
        "#           (2, 0): 'R', (2, 1): 'D', (2, 2): 'R', (2, 3): 'D', (3, 0): 'R', (3, 1): 'R', (3, 2): 'R'}\n",
        "values = {}\n",
        "for state in policy:\n",
        "    values[state] = 0\n",
        "values[(3, 3)] = 2\n",
        "for j in range(2001):\n",
        "  state = enviroment.reset()\n",
        "  stepCounts=0\n",
        "  while (not enviroment.is_terminal(state)) and (stepCounts<20):\n",
        "    nextState, reward = enviroment.move(state, policy, exploreRate=0.01)\n",
        "    values[state] =  values[state]+ 0.1 * ((reward + (0.9 * values[nextState])- values[state]))\n",
        "    state=nextState\n",
        "    stepCounts+=1\n",
        "  if (j%10)==0:\n",
        "    for item in policy:\n",
        "        policy[item] = enviroment.greedyChoose(item, values)\n",
        "    # for state in values:\n",
        "    #   values[state]=0\n",
        "  if (j%200)==0:\n",
        "    print(f\"\\n\\n\\n step:{j}\")\n",
        "    # enviroment.printVaues(values)\n",
        "    enviroment.printPolicy(policy)\n",
        "\n",
        "print(f\"exploited:{enviroment.exploited}  explored:{enviroment.explored}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V42EnhTNSnY",
        "outputId": "698fbceb-4d06-4fc1-fe35-7f02516bb8c2"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            " step:0\n",
            " | D |  | L |  | L |  | L | \n",
            "----------------------------\n",
            " | D |  | L |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | L |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | L |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:200\n",
            " | R |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | U | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:400\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | D |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:600\n",
            " | R |  | L |  | D |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R |  | D | \n",
            "----------------------------\n",
            " | D |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:800\n",
            " | R |  | R |  | R |  | D | \n",
            "----------------------------\n",
            " | U |  | U |  | R |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R |  | D | \n",
            "----------------------------\n",
            " | U |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:1000\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | U |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | U |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:1200\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | U | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:1400\n",
            " | R |  | D |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:1600\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:1800\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | R |  | R |  | U | \n",
            "----------------------------\n",
            "\n",
            "\n",
            "\n",
            " step:2000\n",
            " | R |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | L | \n",
            "----------------------------\n",
            " | U |  | R |  | D |  | D | \n",
            "----------------------------\n",
            " | R |  | R |  | R | \n",
            "----------------------------\n",
            "exploited:19983  explored:213\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Reinforcement-Learning-solving-a-simple-4-4-Gridworld-using-TD0-evaluation-method",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}